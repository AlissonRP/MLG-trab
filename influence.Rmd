---
title: "Investingando a exclusão de Pontos Influentes"
author: "Alisson Rosa e Vítor Pereira "
header-includes:
   - \usepackage[brazil]{babel}
   - \usepackage{bm}
   - \usepackage{float}
geometry: left=1.7cm, right=1.7cm, top=2.5cm, bottom=2.5cm
output:
  bookdown::pdf_document2:
editor_options:
  chunk_output_type: console
indent: true
bibliography: bib.bib
csl: statistics.csl
nocite: '@*'
link-citations: true


---



```{r setup,include=F}

options(digits=3)  #Arrendodamento
options(scipen=999)

ggplot2::theme_set(ggplot2::theme_minimal()) #Tema dos gráficos produzidos no ggplot2
knitr::opts_chunk$set(echo=F,message=F,warning=F,fig.pos = 'H',fig.align = 'center',fig.width=7.8, fig.height=3.85)
#scale_fill_discrete = \(...) ggplot2::scale_fill_brewer(... , palette="Set1") #Fixa a scale do fill dos gráficos do ggplot2

```





```{r}

#citar pokemonfandom
library(tidyverse)
library(tidymodels)
library(themis)
library(patchwork)
#https://www.datanovia.com/en/blog/easy-way-to-expand-color-palettes-in-r/

df = read_csv('https://raw.githubusercontent.com/AlissonRP/MLG-trab/main/Pokemon.csv') |> 
  select(-`#`, -Name, -Total) |> 
  mutate(Legendary = factor(ifelse(Legendary == T, 1, 0)),
         Generation = factor(Generation), `Type 1` = factor(`Type 1`, unique(`Type 1`) ))
         #Fiz esse ajuste para melhorar os gráfios para tornar ele mais compartivo, visto que de um lado a ordem dos tipos tá de um jeito, do outro lado tá de outro
df$Legendary = factor(df$Legendary, levels = c(1,0))
nome <- read.delim("pokemonname.txt")


#cols = length(levels(factor(df$`Type 1`)))
#mycolors  = grDevices::colorRampPalette(brewer.pal(8, "Set3"))(cols)
#scale_fill_discrete = \(...) mycolors

```

```{r}
d=function(df,v1,v2,px){
  df %>% 
    ggplot(aes({{v1}},{{v2}})) +
    geom_point(size=2.1,color="red")+
    ggrepel::geom_text_repel(aes(label=n),size=2.8,point.padding = 0.3)
}
graph<-function(data,l, df){
  data %>% 
    as_tibble() %>% 
      ggplot(aes(as.numeric(row.names(data  %>% as_tibble())),value))+
      geom_point(aes(colour = as.factor(df$Legendary)))+
      geom_hline(yintercept=l, linetype="dashed", color = "black")+
      geom_hline(yintercept=-l, linetype="dashed", color = "black")+
      labs(x="Índice") + labs(color='Lendário') 
}

dffts<-function(fitn,lab1,df){
  n = length(fitn$fitted.values)
  dffits(fitn) %>% 
 graph(2*sqrt(fitn$rank / n),df)+
  labs(title={{lab1}},y="DFfits")
}
Resid<-function(residuon,lab1 = 'padrão', df){
 residuon %>% 
  graph(3,df)+
  geom_hline(yintercept = 0, linetype="dotted", color = "red")+
  labs(title = lab1,  y = "Resíduo")
}
cook<-function(fitn,lab1 = 'aaah', df){
    n = length(fitn$fitted.values)
  cooks.distance(fitn) %>% 
  graph(4/(n-fitn$rank ), df)+
  labs(title = lab1,y = "Distância de Cook")
}
alavanca <- function(fit,df){
  h_bar=fit$rank/length(fit$fitted.values)
  hatvalues(fit) %>%
  graph(3*h_bar,df)+
  labs(title="Alavancagem",y="Medida de Alavancagem")
}
geom_hnp <- function(old_hnp){
  G1 <- with(old_hnp, data.frame(x, lower, upper, median, residuals))
  G1 %>%
  ggplot(aes(x)) +
  geom_point(aes(y = residuals)) +
  geom_line(aes(y = lower)) +
  geom_line(aes(y = upper)) +
  geom_line(aes(y = median), linetype = "dashed")
}

df_dec = df |> 
  mutate(Legendary = ifelse(Legendary == 1, 'Sim','Não'))  |>
  mutate(`Type 2` = fct_explicit_na(`Type 2`, "Sem Tipo 2"), `Type 2` = factor(`Type 2`, unique(`Type 2`)),  `Type 1` = factor(`Type 1`, unique(`Type 1`)))


```




```{r}

#df1 <- df_dec |>

df1 <- df_dec |>
  filter(!row_number() %in% c(262, 430, 415))

df2 <- df_dec |>
  filter(!row_number() %in% c(262, 72, 314, 430, 416, 415)) |>
  filter(!row_number() %in% c(425,424,790)) |>
  filter(!row_number() %in% c(412,121)) |>
  filter(!row_number() %in% c(406,528,787, 410)) |>
  filter(!row_number() %in% c(266,483)) |>
  filter(!row_number() %in% c(153,272, 532)) |>
  filter(!row_number() %in% c(102, 699)) |>
  filter(!row_number() %in% c(778, 300))

df_rf = rand_forest(mode = 'classification', trees = 500) |> 
  set_engine('ranger', importance = "impurity")


df_rl = logistic_reg() |> 
  set_engine('glm')

df_xgb = 
   boost_tree(mode = 'classification') |> 
   set_engine("xgboost")

```

# Análise de Influência

Nesse anexo verificaremos o que aconteceria se tomassemos a decisão de remover os pontos aberrantes, assim iremos desenvolver duas análises sobre a existência de observações atípicas, isto é, vamos considerar dois eventos da exclusão de pontos que exercem peso desproporcional no modelo de Regressão Logística, assim sucedendo com análise de pontos de avalanca, distância de cook, dffits e envelope simulado.


## Exclusão de poucas observações
Nessa seção realizaremos a análise de influência para a remoção de poucas observações, que podem ser pontos influentes, apenas três as observações 262,430 e 415 (sendo os Pokémons conhecidos como: `r paste(nome[c(262, 430, 415),1], sep=' ')`).
```{r model}
set.seed(42)
df_split1 = initial_split(df1 |> select(-`Type 1`,-`Type 2`, -Generation), prop = 0.75 , strata = Legendary)
df_train1 = training(df_split1)
df_test1 = testing(df_split1)
df_vf1 = vfold_cv(df_train1, 10, strata = Legendary)
```

```{r}
df_rec1 = df_train1 |> 
  recipe(Legendary ~.) 

```

```{r}
df_work1 = workflow_set(list(si=df_rec1),
                     list(logistic=df_rl,rf=df_rf, xg = df_xgb), cross=T)

set.seed(42)
doParallel::registerDoParallel(cores=2)

df_tuner1 = df_work1 %>% 
  workflow_map("tune_grid",
               resamples=df_vf1,
               grid=15,
               metrics=metric_set(roc_auc, specificity, sensitivity), verbose=T)
# Não entendi oq isso faz

ffit1 = df_work1 %>% 
  extract_workflow("si_logistic") %>% 
  fit(data = df_train1)

ffit2=df_tuner1 %>% 
  extract_workflow(id='si_rf') %>% 
  fit(df_train1) 

ffit3 = df_tuner1 %>% 
  extract_workflow(id='si_xg') %>% 
  fit(df_train1)
```

### Matrizes de confusões para os modelos propostos 

Não devemos somente avaliar os gráficos de influência, mas também sua previsão, então tem-se que uma medida interessante é a matriz de confusão que pode ser vista como uma tabela que possui os valores reais cruzados com os valores preditos, vejamos para os 3 modelos ajustados como a matriz de confusão fica para os dados de teste:

```{r t1}
ffit1 |> 
  predict(new_data = df_test1) |> bind_cols(df_test1 |> select(Legendary)) |>
  rename(Predição = .pred_class) |> 
  mypdf1::pdf1_tbl_freq2(Legendary , Predição, 'Matriz de confusão para os dados de teste no modelo 
                         de Regressão logística')
```

```{r t2}
ffit2 |> 
  predict(new_data = df_test1) |> bind_cols(df_test1 |> select(Legendary)) |>
  rename(Predição = .pred_class) |> 
  mypdf1::pdf1_tbl_freq2(Legendary , Predição, 'Matriz de confusão para os dados de teste no modelo 
                         de Random Forest')
```

```{r t3}
ffit3 |> 
  predict(new_data = df_test1) |> bind_cols(df_test1 |> select(Legendary)) |>
  rename(Predição = .pred_class) |> 
  mypdf1::pdf1_tbl_freq2(Legendary , Predição, 'Matriz de confusão para os dados de teste no modelo 
                         de XgBoost')
```
Não é perceptível uma diferença relevante das predições dos modelos com exclusão dos pontos aberrantes para a predição dos modelos ajustados no trabalho principal, pois vemos uma piora na Matriz de confusão da Random Forest e uma melhora no modelo do XGBoost.


### Análise de Dignóstico
Vamos nessa seção avaliar a existência de pontos influentes com a exclusão dos pontos influentes anteriores no modelo de Regressão logística.

```{r}
ffit1 = df_work1 %>% 
  extract_workflow("si_logistic") %>% 
  fit(data = df1) |> 
  with(fit) |> with(fit) |> with(fit)
```


#### Alavancagem
Nessa seção veremos as medidas de alavancagem, que informam se uma observação é discrepante em termos de covariável, ou seja, utilizando os resíduos busca medir a discrepância entre o valor observado e o valor ajustado.

```{r f1, fig.cap="Medidas de alavancagem do Modelo com poucas exclusões"}
alavanca(ffit1,df1)+ ggrepel::geom_text_repel(aes(label=1:nrow(df1)), size=2.8, point.padding = 0.3)
```
Podemos perceber que continuam existindo pontos fora do intervalo traçado para alavancagem.


#### Distância de Cook
Tem-se também a distância de Cook, que fornece a influência da observação $i$ sobre todos os $n$ valores ajustados. 

```{r f2, fig.cap="Distância de Cook do Modelo com poucas exclusões"}
cook(ffit1, "Distância do Modelo 1", df1) + ggrepel::geom_text_repel(aes(label=1:nrow(df1)),size=2.8,point.padding = 0.3)
```
A existência de observações possivelmente discrepantes, ainda não foi reduzida visualmente.


#### DFFITS
No diagnóstico DFFITS, que informam o grau de influência que a observação $i$ tem sobre o valor seu próprio valor ajustado $\hat{y_i}$, percebe-se que:

```{r f3, fig.cap="DFFITS do Modelo com poucas exclusões"}
dffts(ffit1, "Dffits do Modelo 1", df1)+ ggrepel::geom_text_repel(aes(label=1:nrow(df1)),size=2.8,point.padding = 0.3)
```

Não observa-se uma mudança perceptível quanto ao achatamento do gráfico.


#### Resíduos

O gráfico de resíduos também é importante para verificarmos visualmente a média dos resíduos e se existe algum valor fora do limite de 3 desvios padrões, pois esses possui baixíssima probabilidade de serem observados, no gráfico abaixo verificamos que todos os estados estão dentro dos limites: 

```{r f4, fig.cap="Resíduos do Modelo com poucas exclusões"}
rstudent(ffit1)|>
Resid("Resíduos do Modelo 1", df1)
```
Para os resíduos, os pontos continuam dentro dos limites desenvolvidos.

#### Envelope Simulado
E por último o envelope simulado, que fornece um vislumbre se a distribuição é adequada para o ajuste
```{r, results = F, fig.show='hide'}
g1 <- hnp::hnp(ffit1, resid.type="deviance", halfnormal = F)
```


```{r f5, fig.cap="Envelope Simulado do Modelo com poucas exclusões"}
g1 |>
  geom_hnp()
```
É visível a melhora comparado ao envelope simulado do modelo principal, mas ainda temos observações fora das bandas simuladas.

## Exclusão de muitas observações
Nessa seção consideraremos o segundo evento, assim realizaremos a análise de influência para a remoção de muitas observações, que podem ser pontos influentes, totalizando um total de 24 pokémons removidos, desses 10 são lendários, ou seja, `r 10/65*100`% de todos os lendários, reduzindo ainda mais a condição rara.  
```{r}
set.seed(42)
df_split12 = initial_split(df2 |> select(-`Type 1`,-`Type 2`, -Generation), prop = 0.75 , strata = Legendary)
df_train12 = training(df_split12)
df_test12 = testing(df_split12)
df_vf12 = vfold_cv(df_train12, 10, strata = Legendary)
```

```{r}
df_rec2 = df_train12 |> 
  recipe(Legendary ~.) 

```

```{r}
df_work12 = workflow_set(list(si=df_rec2),
                     list(logistic=df_rl,rf=df_rf, xg = df_xgb), cross=T)

set.seed(42)
doParallel::registerDoParallel(cores=2)

df_tuner12 = df_work12 %>% 
  workflow_map("tune_grid",
               resamples=df_vf1,
               grid=15,
               metrics=metric_set(roc_auc, specificity, sensitivity), verbose=T)
# Não entendi oq isso faz

ffit12 = df_work12 %>% 
  extract_workflow("si_logistic") %>% 
  fit(data = df_train12)

ffit22=df_tuner12 %>% 
  extract_workflow(id='si_rf') %>% 
  fit(df_train12) 

ffit32 = df_tuner12 %>% 
  extract_workflow(id='si_xg') %>% 
  fit(df_train12)
```

### Matrizes de confusões para os modelos propostos 

Não devemos somente avaliar os gráficos de influência, mas também sua previsão, então tem-se que uma medida interessante é a matriz de confusão que pode ser vista como uma tabela que possui os valores reais cruzados com os valores preditos, vejamos para os 3 modelos ajustados como a matriz de confusão fica para os dados de teste:

```{r ff1}
ffit12 |> 
  predict(new_data = df_test12) |> bind_cols(df_test12 |> select(Legendary)) |>
  rename(Predição = .pred_class) |> 
  mypdf1::pdf1_tbl_freq2(Legendary , Predição, 'Matriz de confusão para os dados de teste no modelo 
                         de Regressão logística')
```

```{r ff2}
ffit22 |> 
  predict(new_data = df_test12) |> bind_cols(df_test12 |> select(Legendary)) |>
  rename(Predição = .pred_class) |> 
  mypdf1::pdf1_tbl_freq2(Legendary , Predição, 'Matriz de confusão para os dados de teste no modelo 
                         de Random Forest')
```

```{r ff3}
ffit3 |> 
  predict(new_data = df_test12) |> bind_cols(df_test12 |> select(Legendary)) |>
  rename(Predição = .pred_class) |> 
  mypdf1::pdf1_tbl_freq2(Legendary , Predição, 'Matriz de confusão para os dados de teste no modelo 
                         de XgBoost')
```
É perceptível uma diferença relevante das predições dos modelos com exclusão de muitos pontos aberrantes para a predição dos modelos ajustados no trabalho principal, é notada uma melhora da sensibilidade em todos os modelos.


### Análise de Dignóstico
Vamos nessa seção avaliar a existência de pontos influentes com a exclusão dos pontos influentes anteriores no modelo de Regressão logística.

```{r}
ffit12 = df_work12 %>% 
  extract_workflow("si_logistic") %>% 
  fit(data = df2) |> 
  with(fit) |> with(fit) |> with(fit)
```


#### Alavancagem
Nessa seção veremos as medidas de alavancagem, que informam se uma observação é discrepante em termos de covariável, ou seja, utilizando os resíduos busca medir a discrepância entre o valor observado e o valor ajustado.

```{r f6, fig.cap="Gráfico das medidas de alavancagem do Modelo com muitas exclusões" }
alavanca(ffit12,df2)+ ggrepel::geom_text_repel(aes(label=1:nrow(df2)), size=2.8, point.padding = 0.3)
```
Ainda continuamos a perceber pontos fora do intervalo traçado para alavancagem.


#### Distância de cook
Tem-se também a distância de cook, que fornece a influência da observação $i$ sobre todos os $n$ valores ajustados. 

```{r f7, fig.cap="Distância de Cook do Modelo com muitas exclusões"}
cook(ffit12, "Distância do Modelo 1", df2) + ggrepel::geom_text_repel(aes(label=1:nrow(df2)),size=2.8,point.padding = 0.3)
```
A existência de observações possivelmente discrepantes, ainda não foi reduzida visualmente.


#### DFFITS
No diagnóstico DFFITS, que informam o grau de influência que a observação $i$ tem sobre o valor seu próprio valor ajustado $\hat{y_i}$, percebe-se que:

```{r f8, fig.cap="DFFITS do Modelo com muitas exclusões"}
dffts(ffit12, "Dffits do Modelo 1", df2)+ ggrepel::geom_text_repel(aes(label=1:nrow(df2)),size=2.8,point.padding = 0.3)
```
Observa-se que o achatamento do gráfico ainda continua nas mesmas proporções.



#### Resíduos

O gráfico de resíduos também é importante para verificarmos visualmente a média dos resíduos e se existe algum valor fora do limite de 3 desvios padrões, pois esses possui baixíssima probabilidade de serem observados, no gráfico abaixo verificamos que todos os estados estão dentro dos limites: 

```{r f9, fig.cap="Resíduos do Modelo com muitas exclusões"}
rstudent(ffit12)|>
Resid("Resíduos do Modelo 1", df2)
```
Para os resíduos, os pontos continuam dentro dos limites desenvolvidos.

#### Envelope Simulado
E por último o envelope simulado, que fornece um vislumbre se a distribuição é adequada para o ajuste
```{r, results = F, fig.show='hide'}
g2 <- hnp::hnp(ffit12, resid.type="deviance", halfnormal = F)
```


```{r f10, fig.cap="Envelope Simulado do Modelo com muitas exclusões"}
g2 |>
  geom_hnp()
```
A melhora comparado ao envelope simulado do modelo principal e ao envelope simulado anterior é notável, mas com todas as remoções ainda não tem-se observações fora das bandas simuladas.

## Testes
Verificando a significância das covariáveis para os modelos com remoções de pontos influentes
```{r tt1}
ffit1 = df_work1 %>% 
  extract_workflow("si_logistic") %>% 
  fit(data = df1)
ffit1 %>%
  extract_fit_parsnip() %>% 
  tidy() %>% 
  mypdf1::pdf1_tbl('Estatísticas do Modelo com poucas remoções')
```


```{r tt2}
ffit12 = df_work12 %>% 
  extract_workflow("si_logistic") %>% 
  fit(data = df2)
ffit12 %>%
  extract_fit_parsnip() %>% 
  tidy() %>% 
  mypdf1::pdf1_tbl('Estatísticas do Modelo com muitas remoções')
```

Então, continua-se com todas as covariáveis significativas para o modelo, as principais diferenças entre os três modelos estão associadas ao Intercepto e a covariável Speed. 


## Critério de seleção de modelos
Avaliando quanto aos critérios de seleção, temos:
```{r tt3}
glance(ffit1) %>% add_row(glance(ffit12)) %>% 
  mypdf1::pdf1_tbl('Critérios de Seleção do Modelo para a Regressão Logistica')
```
Assim o modelo com mais remoções tem os critérios de AIC e BIC melhores, logo podemos reafirmar a decisão tomada anteriormente, pois estaríamos sacrificando uma grande parte da classificação objetivo para buscar o melhor ajuste possível para a análise de influência, mas ainda sem conseguir efetivamente, pois muitas observações estão fora dos limites e principalmente ainda contêm pontos fora das bandas simuladas do envelope, então mesmo com renúncia de uma maior quantidade para a classificação rara ainda não conseguimos atingir o objetivo da análise de influência.

```{r, eval = FALSE}
influ <- influence.measures(fit1)
as.data.frame(influ$is.inf) %>% filter_all(any_vars(. == TRUE)) |> #%>% mypdf1::pdf1_tbl('Diferentes medidas de influência')
rownames(p) |>
  as.numeric() -> del_row
df2 <- df_dec |>
  filter(!row_number() %in% del_row)
nome <- read.delim("pokemonname.txt")
nome |> filter(!row_number() %in% c(262, 72, 314, 430, 416, 415)) |>
  filter(!row_number() %in% c(425,424,790))|>
  filter(row_number() %in% c(412,121))

df_dec |> filter(!row_number() %in% c(262, 72, 314, 430, 416, 415)) |>
  filter(!row_number() %in% c(425,424,790))|> 
  filter(!row_number() %in% c(412,121)) |> 
  filter(!row_number() %in% c(406,528,787, 410)) |>
  filter(!row_number() %in% c(266,483)) |>
  filter(!row_number() %in% c(153,272, 532)) |>
   filter(!row_number() %in% c(102, 699)) |>
  filter(row_number() %in% c(778, 300)) |>
  select(Legendary)
```

# Referências {-}

