---
title: "Explorando a mística de Pokémon: Caracterização de Pokémons Lendários "
author: "Alisson Rosa e Vítor Pereira "
abstract: "Pokémon são criaturas que vivem em todos os lugares, livres na natureza ou com os humanos, cada Pokémom tem seu tipo, pontos fortes e fracos. Com isso o objetivo desse trabalho é analisar suas estatísticas, desenvolvendo gráficos e tabelas e também construindo um modelo que dados as características do Pokémon ele irá nos fornecer uma predição se o Pokémon é lendário ou não."
header-includes:
   - \usepackage[brazil]{babel}
   - \usepackage{bm}
   - \usepackage{float}
geometry: left=1.7cm, right=1.7cm, top=2.5cm, bottom=2.5cm
output:
  bookdown::pdf_document2:
editor_options:
  chunk_output_type: console
indent: true
bibliography: bib.bib
csl: statistics.csl
nocite: '@*'
link-citations: true


---



```{r setup,include=F}

options(digits=3)  #Arrendodamento
options(scipen=999)

ggplot2::theme_set(ggplot2::theme_minimal()) #Tema dos gráficos produzidos no ggplot2
knitr::opts_chunk$set(echo=F,message=F,warning=F,fig.pos = 'H',fig.align = 'center',fig.width=7.8, fig.height=3.85)
#scale_fill_discrete = \(...) ggplot2::scale_fill_brewer(... , palette="Set1") #Fixa a scale do fill dos gráficos do ggplot2

```








# Introdução

Há mais de 20 anos, crianças do mundo inteiro vêm descobrindo o mundo encantado de Pokémon e muitas delas se tornam fãs para a vida toda. Hoje, a família de produtos Pokémon inclui videogames, o jogo de cartas Pokémon Estampas Ilustradas, uma série de animação, filmes, brinquedos, livros e muito mais, mas afinal que são Pokémons?    
Pokémons são criaturas fictícias que pertencem ao universo da série de mesmo nome - Pokémon, são semelhantes a animais do mundo real, podendo viver em bandos ou individualmente, mas também podem ser inspirados em objetos inanimados como velas, sorvetes, chaveiro e outros instrumentos.  Originalmente, a série foi criada como um jogo de videogame e, com a sua popularização, se espalhou para diversos outros formatos, como séries de TV, filmes e livros.

A palavra pokémon é a contração de duas palavras em inglês: pocket, que significa bolso; e monster, que significa monstro. Assim, um pokémon é um "monstro de bolso", na tradução literal, além de ser uma contração esse seria o nome original da série, devido ao lugar onde os Pokémons são armazenados:  as pokébolas, uma espécie de bola pequena para pode-los transportar com mais facilidade, sendo essas basicamente suas casas. Assim as criaturas poderiam descansar após suas batalhas, sendo essa sua principal função explorada no universo Pokémon, em que os monstrinhos lutam de acordo com habilidades da sua tipagem (Fogo, Água, Planta, Pedra, Elétrico, Voador, Lutador, Psíquico, Fantasma, entre outros.).  


```{r}

#citar pokemonfandom
library(tidyverse)
library(tidymodels)
library(themis)
library(patchwork)
#https://www.datanovia.com/en/blog/easy-way-to-expand-color-palettes-in-r/

df = read_csv('https://raw.githubusercontent.com/AlissonRP/MLG-trab/main/Pokemon.csv') |> 
  select(-`#`, -Name, -Total) |> 
  mutate(Legendary = factor(ifelse(Legendary == T, 1, 0)),
         Generation = factor(Generation), `Type 1` = factor(`Type 1`, unique(`Type 1`) ))
         #Fiz esse ajuste para melhorar os gráfios para tornar ele mais compartivo, visto que de um lado a ordem dos tipos tá de um jeito, do outro lado tá de outro
df$Legendary = factor(df$Legendary, levels = c(1,0))

#cols = length(levels(factor(df$`Type 1`)))
#mycolors  = grDevices::colorRampPalette(brewer.pal(8, "Set3"))(cols)
#scale_fill_discrete = \(...) mycolors

```
```{r}
graph<-function(df,l , v){
  df %>% 
    as_tibble() %>% 
      ggplot(aes(as.numeric(row.names(df  %>% as_tibble())),value, color = {{v}}))+
      geom_point()+
      geom_hline(yintercept=l, linetype="dashed", color = "red")+
      geom_hline(yintercept=-l, linetype="dashed", color = "red")+
      labs(x="Índice")
    
}




```


# Análise Descritiva
Cada Pokémon tem seus próprios atributos, como HP (Vida), Attack (Ataque), Defense (Defesa), Speed (Velocidade) e outros mais especificos como:  

* **Generation** (geração): Uma Geração em Pokémon é um grupo de jogos separados de acordo com os Pokémon que estão incluídos nela. Cada geração possui novos Pokémon, ataques e habilidades que não existem nas gerações anteriores. Aqui portanto cada Pokémon tera sua respectiva geração, sendo tratata como uma variável de fator. 

* **Type** (Tipo): São classificações a que estão submetidos todos os Pokémon e técnicas (movimentos). A partir dos tipos, além de ser possível conhecer um pouco mais a natureza de cada Pokémon, é possível também  elaborar estratégias de batalha. Isso porque cada tipo tem vantagens e desvantagens sobre outros tipos. Cada Pokémon pode pertencer a até dois tipos, sendo o primeiro deles o primário (Type 1) e o outro, o secundário (Type 2). Por outro lado, cada movimento tem só um tipo. Um Pokémon pode ter até quatro movimentos, mas elas não precisam ser do mesmo tipo que a criatura.

* **Special Attacks** (Sp. < >) : Ataques Especiais  são movimentos que dão mais dano do que os anteriores, porém possuem um limitador de uso em forma de barra que deve ser carregada. Assim essa variável é dividida em **Sp. Atk** que é a força do ataque especial e  **Sp. Def** que é a defesa do ataque especial.

* **Legendary** (Lendário): Pokémon Lendário (Inglês: Legendary Pokémon) é a denominação dada a uma espécie de Pokémon altamente poderosa, raríssima ou, em alguns casos, até mesmo de um único indivíduo, da qual muito se fala em lendas e mitos no mundo Pokémon, e cuja aparição é extremamente rara. Na seção de modelagem utilizaremos como variável a ser predita o Pokémon ser lendário ou não.

### Constraste de Atributos 
Nessa subseção vamos vislumbrar os atributos dos Pokémon constrastando  entre os lendários e não lendários. Primeiro vejamos a média dos atributos dentre as classificações


```{r}
df_dec = df |> 
  mutate(Legendary = ifelse(Legendary == 1, 'Sim','Não'))  |>
  mutate(`Type 2` = fct_explicit_na(`Type 2`, "Sem Tipo 2"), `Type 2` = factor(`Type 2`, unique(`Type 2`)),  `Type 1` = factor(`Type 1`, unique(`Type 1`)))

mean_leg = df_dec |> 
  group_by(Legendary) |> 
  summarise(across(where(is.numeric), mean),n = n()) 

mean_leg |> 
  mypdf1::pdf1_tbl('Média dos atributos entre as classificações')



```
Assim, como esperado os pokémom lendários possuem atributos superiores (na média) do que os não lendários, note que a força do ataque especial dos pokémon lendários é `r round(mean_leg[2,5] / mean_leg[1,5],2)` vezes maior que os não lendários.  


### Tipos e classificação
Vamos aqui estudar a quantidade de tipos por classificação dos Pokémons. O gráfico \@ref(fig:ref) fornece um vislumbre


```{r ref, fig.cap = "Frequência de Pokémons Lendários e Não Lendários pelo Tipo"}
df_dec |> 
  filter(Legendary == "Não") |> 
  group_by(`Type 1`) |> 
  count() |> 
  ggplot(aes(`Type 1`, n, fill = `Type 1`)) +
  geom_bar(stat = 'identity')+
  coord_flip()+ labs(y="Frequência para os Pokémons não Lendários") +
df_dec |> 
  filter(Legendary == "Sim") |> 
  group_by(`Type 1`) |> 
  count() |> 
   ggplot(aes(`Type 1`, n, fill = `Type 1`)) +
  geom_bar(stat = 'identity')+
  coord_flip() + labs(y="Frequência para os Pokémons Lendários") + plot_layout(guides = "collect") & theme(legend.position = "none") 

```
Com a Figura \@ref(fig:ref) nota-se nos pokémons não lendários temos que os tipos que se destacam numericamente são água e normal, enquanto para os pokémons lendários se destacam psíquico e dragão, ou seja, tipos mais místicos. Com a Figura \@ref(fig:tipo2) podemos ver a quantidade dos tipos secundários dos pokémons.

```{r tipo2, fig.cap = "Frequência de Pokémons Lendários e Não Lendários pelo Tipo secundário"}
df_dec |> 
  filter(Legendary == "Não") |> 
  group_by(`Type 2`) |> 
  count() |> 
  ggplot(aes(`Type 2`, n, fill = `Type 2`)) +
  geom_bar(stat = 'identity')+
  coord_flip()+ labs(y="Frequência para os Pokémons não Lendários") +
df_dec |> 
  filter(Legendary == "Sim") |> 
  group_by(`Type 2`) |> 
  count() |> 
   ggplot(aes(`Type 2`, n, fill = `Type 2`)) +
  geom_bar(stat = 'identity')+
  coord_flip() + labs(y="Frequência para os Pokémons Lendários") + plot_layout(guides = "collect") & theme(legend.position = "none")  

```
Identifica-se pela Figura \@ref(fig:tipo2), que em ambas as classificações os pokémons sem tipo secundários são a classificação majoritária, seguido pelo tipo voador, que se destaca para os pokémons lendários. Para os pokémons lendários também se salientas os tipos dragão, lutador e psíquico, enquanto que para os pokémons não lendários temos os tipos venenoso, terrestre e psíquico no top 5 de mais recorrentes.



### Lançamento por gerações
Nessa subseção iremos analisar a quantidade de pokémons lançados em cada geração e comparar com o desenvolvimento de novos pokémons lendários, começaremos analisando a frequência de pokémons novos por geração na Figura \@ref(fig:g1).
```{r g1, fig.cap = "Frequência lançados por geração"}
df_dec |> 
  group_by(Generation) |> 
  count() |> 
  ggplot(aes(Generation, n, fill = Generation)) +
  geom_bar(stat = 'identity')+ labs(y="Novos pokémons") + theme(legend.position = "none")
```
Com a Figura \@ref(fig:g1), podemos notar uma "sazonalidade" para o desenvolvimento de pokémons, visto que as gerações ímpares se sobresãem em número com todas com pelo menos 160 pokémons novos e para as gerações pares tem-se uma queda notável, com um mínimo 82 novos pokémons na geração 6 e um máximo de 121 na geração 5. A primeira geração ainda é imbatível com a quantidade de lançamentos de pokémons, 166, no entanto, ganha por apenas 1 da quinta geração. Para o desenvolvimento de Pokémons lendários podemos ver a representação com a Figura \@ref(fig:g2).

```{r g2, fig.cap = "Frequência de novos pokémons lendários por geração"}
df_dec |> 
  filter(Legendary == "Sim") |> 
  group_by(Generation) |> 
  count() |> 
  ggplot(aes(Generation, n, fill = Generation)) +
  geom_bar(stat = 'identity')+
  labs(y="Novos pokémons") + theme(legend.position = "none")
```

Antagônico a Figura \@ref(fig:g1), na Figura \@ref(fig:g2) a terceira e quinta gerações se evidenciam, com a criação de pokémons lendários, o fato deve-se que nas primeiras gerações os lendários estavam em torno do "Trio de Aves Lendárias" e "Trio de Cães Lendários", enquanto que nas próxima gerações foi se desenvolvendo e explicando a criação e manutenção do Universo Pokémon por suas espécies lendárias.

# Análise Preditiva
Vamos aqui utilizar como variável de desfecho a classificação do pokémom, sendo portanto Lendário ou não, vamos testar a saber 3 modelos para predição: Random Forest, Regressão logística e Xgboost. Como métrica de escolha de modelo vamos utilizar a sensibilidade e não a acurácia como erroneamente muitos fazem, pois como vimos, a proporção de pokémons não lendários é `r round(df |> group_by(Legendary) |> count() |> mutate(prop = n/nrow(df)) |> with(prop[1]), 2)`, portanto se os modelos predizerem não lendário para todas observações teremos `r round(df |> group_by(Legendary) |> count() |> mutate(prop = n/nrow(df)) |> with(prop[1]), 2)*100`% de acurácia.

```{r model}
set.seed(42)
df_split = initial_split(df |> select(-`Type 1`,-`Type 2`, -Generation), prop = 0.75 , strata = Legendary)
df_train = training(df_split)
df_test = testing(df_split)
df_vf = vfold_cv(df_train, 10, strata = Legendary)
```

```{r}
df_rec1 = df_train |> 
  recipe(Legendary ~.) 

df_rf = rand_forest(mode = 'classification', trees = 500) |> 
  set_engine('ranger', importance = "impurity")


df_rl = logistic_reg() |> 
  set_engine('glm')

df_xgb = 
   boost_tree(mode = 'classification') |> 
   set_engine("xgboost")


```

```{r}
df_work = workflow_set(list(si=df_rec1),
                     list(logistic=df_rl,rf=df_rf, xg = df_xgb), cross=T)
```
```{r}
set.seed(42)
doParallel::registerDoParallel(cores=2)
df_tuner = df_work %>% 
  workflow_map("tune_grid",
               resamples=df_vf,
               grid=15,
               metrics=metric_set(roc_auc, specificity, sensitivity), verbose=T)

```



## Regressão Logística


Regressão logistíca é um dos principais modelo estatístico atuais, pode ser descrito ^[Ou também um caso simples de uma neural network.] como um modelo linear generalizado (MLG). Vamos considerar $p$ a probabilidade de sucesso de uma certa variável binária, ou seja uma variável que tem distribuição Bernoulli.

O MLG usando como função de ligação logit pode ser escrito da seguinte maneira:
$$
\text{log}\bigg(\dfrac{p}{1-p}\bigg)=\sum_{i=1}^{n}\beta_iX_i \quad \text{onde} \quad X_0=1
$$
Definindo $\sum_{i=1}^{n}\beta_iX_i$ como $\eta$  fica fácil ver que $p$ pode ser escrito como:

$$
p = \dfrac{e^{\eta}}{1+e^{\eta}}
$$
Apesar do modelo de regressão logística ser mais utilizado em análise inferencial, podemos também fazer predições de classes binárias se colocarmos um limiar para a saída ($p$) do modelo ser classificado como de certa classe, em outras palavras se $p \geq T$, onde T é um certo limite pré estabelecido, como não temos em mãos o modelo populacional trabalhamos com a predição $\hat{p}$ para a classificação do Pokémon ser lendário, aqui utilizamos $T = 0.5$.


```{r}
fit1 = df_work %>% 
  extract_workflow("si_logistic") %>% 
  fit(data = df_train)
```



## Random Forest

Árvores de decisão são modelos que já existem a um certo tempo, apesar de terem uma grande vantagem em interpretabilidade são fracas em termos preditivos, assim a  idéia de Random Forest é combinar diversas árvores alterando (bootstrap) o conjunto de treinamento  de cada uma elas para gerar diversidade na predição, as árvores podem individualmente não serem fortes preditoras mas queremos no geral a predição combinada delas seja. Uma peculiaridade da Random Forest é que podemos ver a importância^[Importância aqui: Decréscimo médio na impureza.] das variáveis, o que é ilustrado pelo gráfico \@ref(fig:vip)




```{r vip, fig.cap='Importância das variáveis na Random Forest nos dados de treino'}
fit2=df_tuner %>% 
  extract_workflow(id='si_rf') %>% 
  fit(df_train) 

fit2 %>% 
extract_fit_parsnip() %>% 
  vip::vip(num_features = 10, mapping = aes_string(fill = "Variable"))+
  labs(y="Importância")
```

## Xgboost
É notável que algoritmos de boosting atualmente são o estado da arte para dados estruturados, nele as árvores vão crescendo usando informações das árvores anteriores, isso quer dizer que  não fazemos bootstrap dos dados igual em Random Forest, mas cada árvore trabalha  com uma versão diferente dos dados originais, vamos aqui ajustar xgboost para comparar com os modelos anteriores.


```{r, include=FALSE}
fit3 = df_tuner %>% 
  extract_workflow(id='si_xg') %>% 
  fit(df_train)
```


Uma medida interessante é a matriz de confusão que pode ser vista como uma tabela que possui os valores reais cruzados com os valores preditos, vejamos para os 3 modelos ajustados como a matriz de confusão fica para os dados de teste:

```{r}
fit1 |> 
  predict(new_data = df_test) |> bind_cols(df_test |> select(Legendary)) |>
  rename(Predição = .pred_class) |> 
  mypdf1::pdf1_tbl_freq2(Legendary , Predição, 'Matriz de confusão para os dados de teste no modelo 
                         de Regressão logística')
```
comentários



```{r}
fit2 |> 
  predict(new_data = df_test) |> bind_cols(df_test |> select(Legendary)) |>
  rename(Predição = .pred_class) |> 
  mypdf1::pdf1_tbl_freq2(Legendary , Predição, 'Matriz de confusão para os dados de teste no modelo 
                         de Random Forest')
```
comentários


```{r}
fit3 |> 
  predict(new_data = df_test) |> bind_cols(df_test |> select(Legendary)) |>
  rename(Predição = .pred_class) |> 
  mypdf1::pdf1_tbl_freq2(Legendary , Predição, 'Matriz de confusão para os dados de teste no modelo 
                         de XgBoost')
```
Da matriz de confusão podemos derivar as seguintes métricas:  

* Valor predito positivo (`ppv`): Que é definido como sendo a proporção de predições positivas que foram corretamentes previstas 
* Valor predito negativo (`npv`): Por definição é a proporção de predições negativas que foram corretamentes previstas  
* Sensibilidade (`sens`): É a proporção de previsões corretas dos casos positivos  
* Especificidade (`spec`): É a proporção de previsões corretas dos casos negativos



O gráfico ref fornece o vislumbre de como as métricas se comportam para os 3 modelos ajustados na validação cruzada
```{r, fig.cap = 'Métricas dos modelos na validação cruzada'}
autoplot(df_tuner) +
  labs(x = 'Rank do modelo', y= 'Métrica')
```


E para os dados de teste temos: 

```{r yeah}
#Cria as métricas nos dados de teste
metric = function(id){
  df_tuner %>% 
  extract_workflow(id=id) |>
  last_fit(split = df_split, metrics = metric_set(roc_auc, sens, spec, ppv, npv)) |> 
  collect_metrics()
}
#Cria o dataframe das métricas
vetur = function(final){
   final_logis = final|> with(.estimate) 
 names(final_logis) = final |> with(.metric)
 final_logis |> 
  as.list() |> 
  data.frame()
  
}

final_log = metric('si_logistic')
final_rf = metric('si_rf')
final_xg = metric('si_xg')
 
 
 
 #faz a tabela
oh_yeah = vetur(final_log) |> 
  bind_rows(vetur(final_rf)) |> 
  bind_rows(vetur(final_xg)) |> 
  bind_cols(tibble(Modelo = c('Regressão Logistica','Random Forest','xgboost'))) |> 
  select(Modelo, everything()) 

oh_yeah |> 
  mypdf1::pdf1_tbl('Métricas nos dados de teste')
 
 
```
Assim vemos pela tabela \@ref(tab:yeah) que o modelo que maximizou a sensibilidade é `r oh_yeah |> filter(sens == max(sens)) |> select(Modelo)`



# Análise Inferencial

## Análise de Dignóstico
Vamos nessa seção avaliar a existência de pontos influentes no modelo de Regressão logística

```{r}
fit1 = df_work %>% 
  extract_workflow("si_logistic") %>% 
  fit(data = df) |> 
  with(fit) |> with(fit) |> with(fit)
```


`


### Distância de cook
Tem-se também a distância de cook, que fornece a influência da observação $i$ sobre todos os $n$ valores ajustados, 

```{r}
diagreg::cook(fit1)
```


### Dffits
No diagnóstico dffits, que informam o grau de influência que a observação $i$ tem sobre o valor seu próprio valor ajustado $\hat{y_i}$, percebe-se que:

```{r}
diagreg::dffts(fit1)
```

O gráfico de resíduos também é importante para verificarmos visualmente a média dos resíduos e se existe algum valor fora do limite de 3 desvios padrões, pois esses possui baixíssima probabilidade de serem observados, no gráfico abaixo verificamos que todos os estados estão dentro dos limites: 



```{r}
diagreg::Resid(fit1)
```


E por último o envelope simulado, que fornce um vislumbre se a distribuição é adequada para o ajuste
```{r, results = F, fig.show='hide'}
g1 <- hnp::hnp(fit1, resid.type="deviance", halfnormal = F)
G1 <- with(g1, data.frame(x, lower, upper, median, residuals))
```

```{r}
G1 %>%
ggplot(aes(x)) +
  geom_point(aes(y = residuals)) +
  geom_line(aes(y = lower)) +
  geom_line(aes(y = upper)) +
  geom_line(aes(y = median), linetype = "dashed")
```

Você faz referência cruzada de figuras assim: Figura \@ref(fig:crfgraph)


# Referências {-}




